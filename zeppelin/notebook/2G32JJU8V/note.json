{
  "paragraphs": [
    {
      "title": "Custom Neo4j UDFs and Spark",
      "text": "",
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.660",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1615887249633_-1240825801",
      "id": "paragraph_1602086954178_-84212442",
      "dateCreated": "2021-03-16 09:34:09.633",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// This sample notebook will show you how to create custom UDFs for Spark using Neo4j\n\n// Because the Neo4j Connector for Apache Spark comes with a Neo4j Java driver packaged \n// into it, you can natively use the Neo4j Java driver as part of your spark programs.\nimport org.neo4j.driver.{Driver, GraphDatabase, Session, Result, Record, AuthTokens, Transaction, TransactionWork};\n\nval user \u003d \"neo4j\"\nval password \u003d \"password\"\nval uri \u003d \"bolt://neo4j\"\n\nval driver \u003d GraphDatabase.driver( uri, AuthTokens.basic( user, password ) );\nval session \u003d driver.session\n\n// Write some sample data for testing purposes, using some simple geneaology data.\nval result \u003d session.run(\"\"\"\n   CREATE (bob:Person { name: \"Bob\" })\n        -[:CHILD]-\u003e(sarah:Person { name: \"Sarah\" })\n            -[:CHILD]-\u003e(kurt:Person { name: \"Kurt\" })\n   CREATE (sarah)-[:CHILD]-\u003e(:Person { name: \"Martha\" })\n   RETURN true\n\"\"\")\n\nprintln(\"Created data: \" + result.single.get(0))",
      "user": "anonymous",
      "dateUpdated": "2021-03-18 11:00:57.532",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Created data: TRUE\nimport org.neo4j.driver.{Driver, GraphDatabase, Session, Result, Record, AuthTokens, Transaction, TransactionWork}\nimport org.apache.spark.sql.functions.udf\n\u001b[1m\u001b[34muser\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d neo4j\n\u001b[1m\u001b[34mpassword\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d zeppelin\n\u001b[1m\u001b[34muri\u001b[0m: \u001b[1m\u001b[32mString\u001b[0m \u003d bolt://neo4j\n\u001b[1m\u001b[34mdriver\u001b[0m: \u001b[1m\u001b[32morg.neo4j.driver.Driver\u001b[0m \u003d org.neo4j.driver.internal.InternalDriver@6ce7b7bd\n\u001b[1m\u001b[34msession\u001b[0m: \u001b[1m\u001b[32morg.neo4j.driver.Session\u001b[0m \u003d org.neo4j.driver.internal.InternalSession@5b3624fc\n\u001b[1m\u001b[34mresult\u001b[0m: \u001b[1m\u001b[32morg.neo4j.driver.Result\u001b[0m \u003d org.neo4j.driver.internal.InternalResult@3ced45cc\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1615887249662_-1110764050",
      "id": "paragraph_1602083886753_382342748",
      "dateCreated": "2021-03-16 09:34:09.663",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Let\u0027s define a function to count descendants!\nimport org.neo4j.driver.Values.parameters;\n\ndef countDescendants(personName: String) : Integer \u003d {\n    val session \u003d driver.session\n    val result \u003d session.run(\"\"\"\n       MATCH (:Person { name: $name })-[:CHILD*]-\u003e(child:Person)\n       RETURN count(distinct(child)) as descendants\n    \"\"\", parameters(\"name\", personName))\n    \n    return result.single.get(0).asInt\n}\n\nprintln(\"Bob\u0027s descendants: \" + countDescendants(\"Bob\"))\n\n// Looking good so far.\n",
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.664",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "Bob\u0027s descendants: 3\nimport org.neo4j.driver.Values.parameters\n\u001b[1m\u001b[34mcountDescendants\u001b[0m: \u001b[1m\u001b[32m(personName: String)Integer\u001b[0m\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1615887249664_180067925",
      "id": "paragraph_1602082581879_1592744541",
      "dateCreated": "2021-03-16 09:34:09.664",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Take this simple function and make it a UDF.\n// Creating scala UDFs for Spark:\n// https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-udfs.html\nimport org.apache.spark.sql.functions.udf\n\nval countDescendantsUDF \u003d udf(countDescendants _)",
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.665",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "import org.apache.spark.sql.functions.udf\n\u001b[1m\u001b[34mcountDescendantsUDF\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.expressions.UserDefinedFunction\u001b[0m \u003d UserDefinedFunction(\u003cfunction1\u003e,IntegerType,Some(List(StringType)))\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1615887249664_-543129956",
      "id": "paragraph_1602082621947_-1897965463",
      "dateCreated": "2021-03-16 09:34:09.664",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Let\u0027s make some data in a dataframe.\n\nval dataset \u003d Seq((0, \"Bob\"), (1, \"Sarah\"), (2, \"Kurt\")).toDF(\"id\", \"name\")\ndataset.show()",
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.671",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+\n| id| name|\n+---+-----+\n|  0|  Bob|\n|  1|Sarah|\n|  2| Kurt|\n+---+-----+\n\n\u001b[1m\u001b[34mdataset\u001b[0m: \u001b[1m\u001b[32morg.apache.spark.sql.DataFrame\u001b[0m \u003d [id: int, name: string]\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1615887249666_1463524141",
      "id": "paragraph_1602086727973_-414703294",
      "dateCreated": "2021-03-16 09:34:09.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Finally, apply the UDF to our dataset.\n\ndataset.withColumn(\"descendants\", countDescendantsUDF(\u0027name)).show",
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.672",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "+---+-----+-----------+\n| id| name|descendants|\n+---+-----+-----------+\n|  0|  Bob|          3|\n|  1|Sarah|          2|\n|  2| Kurt|          0|\n+---+-----+-----------+\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1615887249671_-1885629185",
      "id": "paragraph_1602086830483_1984315201",
      "dateCreated": "2021-03-16 09:34:09.671",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "anonymous",
      "dateUpdated": "2021-03-16 09:34:09.672",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false,
          "completionKey": "TAB",
          "completionSupport": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "fontSize": 9.0,
        "editorHide": false,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1615887249672_67082680",
      "id": "paragraph_1602086900551_-1781421734",
      "dateCreated": "2021-03-16 09:34:09.672",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Scala UDFs",
  "id": "2G32JJU8V",
  "noteParams": {},
  "noteForms": {},
  "angularObjects": {
    "spark:shared_process": []
  },
  "config": {
    "isZeppelinNotebookCronEnable": false
  },
  "info": {}
}